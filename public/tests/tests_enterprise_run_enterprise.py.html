<!doctype html><html><head><meta charset="utf-8"><title>Tests: tests\enterprise\run_enterprise.py</title><link rel="stylesheet" href="tests.css"></head><body><div class="wrap"><h1>Tests: tests\enterprise\run_enterprise.py</h1><p><a href="index.html">Back to tests index</a></p><h2>Source</h2><pre class="source">#!/usr/bin/env python3
&quot;&quot;&quot;
Enterprise test runner - live-first, adaptive, logged

Run this script to execute the full Verity enterprise test suite against a
live deployment. The runner always attempts live calls (use `TEST_URL` to
point to the target) and records results under `test-vault/`.

Behavior:
- Runs many endpoint checks (health, providers, image-forensics, realtime,
  verify, research-assistant, social-media, and more).
- Writes a detailed JSON run log: `test-vault/enterprise-&lt;timestamp&gt;.json`.
- Maintains a history file `test-vault/enterprise-history.json` used to
  adjust future runs (add variants for repeatedly-failing tests).
- Produces basic suggestions per failure to help prioritize fixes.

Designed to run on developer machines or CI where environment variables
for external providers are configured. If an endpoint returns 4xx/5xx the
failure will be logged and used to adapt the next run.
&quot;&quot;&quot;
from __future__ import annotations

import json
import os
import sys
import time
import traceback
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import requests


ROOT = Path(__file__).resolve().parents[2]
VAULT = ROOT / &quot;test-vault&quot;
VAULT.mkdir(exist_ok=True)

TEST_URL = os.getenv(&quot;TEST_URL&quot;, &quot;http://localhost:8000&quot;)
API_KEY = os.getenv(&quot;TEST_API_KEY&quot;) or os.getenv(&quot;VERITY_TEST_KEY&quot;)
HEADERS = {&quot;Content-Type&quot;: &quot;application/json&quot;}
if API_KEY:
    HEADERS[&quot;Authorization&quot;] = f&quot;Bearer {API_KEY}&quot;

HISTORY_FILE = VAULT / &quot;enterprise-history.json&quot;


def timestamp() -&gt; str:
    return datetime.utcnow().isoformat() + &quot;Z&quot;


def load_history() -&gt; Dict[str, Any]:
    if HISTORY_FILE.exists():
        try:
            return json.loads(HISTORY_FILE.read_text())
        except Exception:
            return {&quot;runs&quot;: []}
    return {&quot;runs&quot;: []}


def save_history(history: Dict[str, Any]):
    HISTORY_FILE.write_text(json.dumps(history, indent=2))


def log_run(result: Dict[str, Any]):
    fname = VAULT / f&quot;enterprise-{int(time.time())}.json&quot;
    fname.write_text(json.dumps(result, indent=2))
    # Append to history
    history = load_history()
    history.setdefault(&quot;runs&quot;, []).append({
        &quot;time&quot;: result[&quot;started_at&quot;],
        &quot;summary&quot;: {&quot;passed&quot;: result[&quot;summary&quot;][&quot;passed&quot;], &quot;failed&quot;: result[&quot;summary&quot;][&quot;failed&quot;]},
        &quot;details_path&quot;: str(fname.name),
    })
    # Keep only last 100 runs
    history[&quot;runs&quot;] = history[&quot;runs&quot;][-100:]
    save_history(history)


def suggest_for_failure(test_name: str, details: Dict[str, Any]) -&gt; str:
    code = details.get(&quot;status_code&quot;)
    body = details.get(&quot;body&quot;)
    if code and 500 &lt;= int(code) &lt; 600:
        return &quot;Server error: investigate provider integrations and retry logic; add exponential backoff and circuit-breaker tuning.&quot;
    if code == 429:
        return &quot;Rate limited: increase capacity, add per-provider rate limits, or stagger calls in tests.&quot;
    if code and 400 &lt;= int(code) &lt; 500:
        return &quot;Client error: validate payload and auth; ensure API keys and headers are correct.&quot;
    if isinstance(body, dict) and not body.get(&quot;success&quot;, True):
        return body.get(&quot;message&quot;) or &quot;API returned unsuccessful response; inspect provider responses and input data.&quot;
    return &quot;No specific suggestion available; inspect logs and repeat the test with verbose provider tracing.&quot;


def run_check(method: str, path: str, payload: Any = None, timeout: int = 30) -&gt; Dict[str, Any]:
    url = TEST_URL.rstrip(&quot;/&quot;) + path
    start = time.time()
    try:
        if method == &quot;GET&quot;:
            r = requests.get(url, headers=HEADERS, timeout=timeout)
        else:
            r = requests.post(url, headers=HEADERS, json=payload, timeout=timeout)
        elapsed = time.time() - start
        body = None
        try:
            body = r.json()
        except Exception:
            body = r.text
        success = r.status_code == 200 and (not isinstance(body, dict) or body.get(&quot;success&quot;, True) is not False)
        return {
            &quot;name&quot;: path,
            &quot;method&quot;: method,
            &quot;url&quot;: url,
            &quot;status_code&quot;: r.status_code,
            &quot;duration_ms&quot;: int(elapsed * 1000),
            &quot;body&quot;: body,
            &quot;success&quot;: bool(success),
        }
    except Exception as e:
        return {&quot;name&quot;: path, &quot;method&quot;: method, &quot;url&quot;: url, &quot;status_code&quot;: None, &quot;duration_ms&quot;: None, &quot;body&quot;: str(e), &quot;success&quot;: False}


def main():
    started = timestamp()
    history = load_history()

    # Base test matrix
    tests: List[Dict[str, Any]] = [
        {&quot;name&quot;: &quot;health&quot;, &quot;method&quot;: &quot;GET&quot;, &quot;path&quot;: &quot;/health&quot;},
        {&quot;name&quot;: &quot;health_deep&quot;, &quot;method&quot;: &quot;GET&quot;, &quot;path&quot;: &quot;/health/deep&quot;},
        {&quot;name&quot;: &quot;providers&quot;, &quot;method&quot;: &quot;GET&quot;, &quot;path&quot;: &quot;/providers&quot;},
        {&quot;name&quot;: &quot;providers_health&quot;, &quot;method&quot;: &quot;GET&quot;, &quot;path&quot;: &quot;/providers/health&quot;},
        {&quot;name&quot;: &quot;verify&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/verify&quot;, &quot;payload&quot;: {&quot;claim&quot;: &quot;The sky is blue.&quot;, &quot;source&quot;: &quot;unit-test&quot;}},
        {&quot;name&quot;: &quot;v3_batch_verify&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/v3/batch-verify&quot;, &quot;payload&quot;: {&quot;claims&quot;: [&quot;Water is wet.&quot;, &quot;The moon is made of cheese.&quot;]}},
        {&quot;name&quot;: &quot;image_forensics&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/image-forensics&quot;, &quot;payload&quot;: {&quot;image_url&quot;: &quot;https://example.com/sample.jpg&quot;}},
        {&quot;name&quot;: &quot;realtime_stream&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/realtime-stream&quot;, &quot;payload&quot;: {&quot;text&quot;: &quot;This is a viral test message&quot;, &quot;metadata&quot;: {&quot;platform&quot;: &quot;test&quot;}}},
        {&quot;name&quot;: &quot;research_assistant&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/research-assistant&quot;, &quot;payload&quot;: {&quot;query&quot;: &quot;recent research on misinformation detection&quot;}},
        {&quot;name&quot;: &quot;social_media&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/social-media&quot;, &quot;payload&quot;: {&quot;url&quot;: &quot;https://twitter.com/example/status/1&quot;}},
        {&quot;name&quot;: &quot;source_credibility&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/source-credibility&quot;, &quot;payload&quot;: {&quot;url&quot;: &quot;https://example.com/article&quot;}},
        {&quot;name&quot;: &quot;statistics_validator&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/statistics-validator&quot;, &quot;payload&quot;: {&quot;text&quot;: &quot;10% of people do X&quot;}},
    ]

    # Adaptive: if recent runs show repeated failures, add additional variants for those tests
    recent = history.get(&quot;runs&quot;, [])[-5:]
    failed_names = set()
    for r in recent:
        # read details file if exists
        details_path = VAULT / r.get(&quot;details_path&quot;, &quot;&quot;)
        if details_path.exists():
            try:
                content = json.loads(details_path.read_text())
                for t in content.get(&quot;tests&quot;, []):
                    if not t.get(&quot;success&quot;):
                        failed_names.add(t.get(&quot;name&quot;) or t.get(&quot;url&quot;))
            except Exception:
                continue

    # For each repeatedly failing test, add a variant payload to exercise edge cases
    for name in list(failed_names):
        if &quot;image-forensics&quot; in name or &quot;image_forensics&quot; in name:
            tests.append({&quot;name&quot;: &quot;image_forensics_variant&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/image-forensics&quot;, &quot;payload&quot;: {&quot;image_url&quot;: &quot;https://example.com/deepfake.png&quot;, &quot;sensitivity&quot;: &quot;high&quot;}})
        if &quot;realtime&quot; in name:
            tests.append({&quot;name&quot;: &quot;realtime_high_viral&quot;, &quot;method&quot;: &quot;POST&quot;, &quot;path&quot;: &quot;/tools/realtime-stream&quot;, &quot;payload&quot;: {&quot;text&quot;: &quot;Breaking: major event causing massive spread&quot;, &quot;metadata&quot;: {&quot;platform&quot;: &quot;twitter&quot;, &quot;shares&quot;: 100000}}})

    results: List[Dict[str, Any]] = []

    for t in tests:
        print(f&quot;Running {t[&#x27;name&#x27;]} -&gt; {t[&#x27;path&#x27;]}&quot;)
        try:
            res = run_check(t.get(&quot;method&quot;, &quot;POST&quot;), t[&quot;path&quot;], payload=t.get(&quot;payload&quot;))
            # normalize name
            res[&quot;name&quot;] = t[&quot;name&quot;]
            results.append(res)
            if not res.get(&quot;success&quot;):
                print(f&quot;  FAIL {t[&#x27;name&#x27;]} status={res.get(&#x27;status_code&#x27;)} url={res.get(&#x27;url&#x27;)}&quot;)
        except Exception:
            tb = traceback.format_exc()
            results.append({&quot;name&quot;: t[&quot;name&quot;], &quot;success&quot;: False, &quot;error&quot;: tb})

    passed = sum(1 for r in results if r.get(&quot;success&quot;))
    failed = len(results) - passed

    summary = {&quot;total&quot;: len(results), &quot;passed&quot;: passed, &quot;failed&quot;: failed}

    suggestions = []
    for r in results:
        if not r.get(&quot;success&quot;):
            suggestions.append({&quot;test&quot;: r.get(&quot;name&quot;), &quot;suggestion&quot;: suggest_for_failure(r.get(&quot;name&quot;), r)})

    run_result = {
        &quot;started_at&quot;: started,
        &quot;finished_at&quot;: timestamp(),
        &quot;test_url&quot;: TEST_URL,
        &quot;summary&quot;: summary,
        &quot;tests&quot;: results,
        &quot;suggestions&quot;: suggestions,
    }

    log_run(run_result)

    # Print concise summary
    print(json.dumps({&quot;summary&quot;: summary, &quot;suggestions_count&quot;: len(suggestions)}, indent=2))

    # Exit code non-zero if any test failed
    if failed &gt; 0:
        print(&quot;One or more enterprise tests failed; see test-vault for details.&quot;)
        sys.exit(2)


if __name__ == &quot;__main__&quot;:
    main()
</pre></div></body></html>